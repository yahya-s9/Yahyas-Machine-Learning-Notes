https://arxiv.org/abs/2510.04871

Author: Alexia Jolicouer-Martineau
- Samsung SAIL Montreal

- Abstract
- 1. Introduction
- 2. Background
	- 2.1 Structure and goal 
	- 2.2 recursion at two different frequencies
	- 2.3 Fixed-point recursion with 1-step gradient approximation
	- 2.4 deep supervision
	- 2.5 adaptive computational time
	- 2.6 deep supervision and 1-step gradient approximations replace BPTT
	- 2.7 Summary of HRM
- 3. Target for improvements in Hierarchical Reasoning Models
	- 3.1 Implicit Function Theorem with 1-step gradient approximation
	- 3.2 Twice the forward passes with adaptive computation time
	- 3.3 hierarchical interpretation based on comple biological arguments
- 4. Tiny recursion models
	- 4.1 no fixed-point theorem required
	- 2.2 simpler reinterpretation of Z_h and Z_l
	- 4.3 single network
	- 4.4 less is more
	- 4.5 attention-free architecture for tasks with small fixed context length
	- 4.6 no additional forward passes needed with ACT
	- 4.7 exponential moving average
	- 4.8 optimal the number of recursions
- 5. Results
- 6. Conclusion
- Hyper-parameters and setup
- Ideas that failed
